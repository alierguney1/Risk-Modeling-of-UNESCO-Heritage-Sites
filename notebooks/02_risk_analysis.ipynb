{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNESCO Heritage Sites Risk Modeling - Risk Analysis\n",
    "\n",
    "## Notebook 02: Risk Score Analysis and Insights\n",
    "\n",
    "**Purpose**: Analyze calculated risk scores, identify patterns, and generate insights about heritage site vulnerabilities.\n",
    "\n",
    "**Contents**:\n",
    "1. Load risk scores and merge with site data\n",
    "2. Risk score distributions and statistics\n",
    "3. Sub-score analysis (urban, climate, seismic, fire, flood, coastal)\n",
    "4. Correlation analysis between risk factors\n",
    "5. High-risk site identification\n",
    "6. Anomaly detection results\n",
    "7. Geographic risk patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import text\n",
    "import warnings\n",
    "\n",
    "# Import project modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.db.connection import get_session, engine\n",
    "from config.settings import DEFAULT_WEIGHTS\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Risk Scores and Site Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sites with risk scores\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    hs.id, hs.whc_id, hs.name, hs.country, hs.category,\n",
    "    hs.in_danger, hs.area_hectares,\n",
    "    ST_X(hs.geom) as longitude, ST_Y(hs.geom) as latitude,\n",
    "    rs.urban_density_score,\n",
    "    rs.climate_anomaly_score,\n",
    "    rs.seismic_risk_score,\n",
    "    rs.fire_risk_score,\n",
    "    rs.flood_risk_score,\n",
    "    rs.coastal_risk_score,\n",
    "    rs.composite_risk_score,\n",
    "    rs.risk_level,\n",
    "    rs.is_anomaly,\n",
    "    rs.isolation_forest_score\n",
    "FROM unesco_risk.heritage_sites hs\n",
    "JOIN unesco_risk.risk_scores rs ON hs.id = rs.site_id\n",
    "ORDER BY rs.composite_risk_score DESC;\n",
    "\"\"\"\n",
    "\n",
    "risk_df = pd.read_sql(query, engine)\n",
    "print(f\"Loaded {len(risk_df)} sites with risk scores\")\n",
    "risk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display risk weights being used\n",
    "print(\"=\" * 60)\n",
    "print(\"RISK WEIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "for factor, weight in DEFAULT_WEIGHTS.items():\n",
    "    print(f\"{factor:30s}: {weight:.2f} ({weight*100:.0f}%)\")\n",
    "print(f\"\\nTotal: {sum(DEFAULT_WEIGHTS.values()):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Risk Score Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk level distribution\n",
    "print(\"=\" * 60)\n",
    "print(\"RISK LEVEL DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "risk_level_counts = risk_df['risk_level'].value_counts()\n",
    "print(risk_level_counts)\n",
    "print(f\"\\nPercentages:\")\n",
    "print((risk_level_counts / len(risk_df) * 100).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk level bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "risk_order = ['low', 'medium', 'high', 'critical']\n",
    "colors_map = {'low': 'green', 'medium': 'yellow', 'high': 'orange', 'critical': 'red'}\n",
    "\n",
    "counts = risk_df['risk_level'].value_counts().reindex(risk_order, fill_value=0)\n",
    "bars = plt.bar(range(len(counts)), counts.values, \n",
    "               color=[colors_map[level] for level in counts.index])\n",
    "\n",
    "plt.xticks(range(len(counts)), counts.index.str.capitalize())\n",
    "plt.ylabel('Number of Sites', fontsize=12)\n",
    "plt.title('Risk Level Distribution', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, (bar, count) in enumerate(zip(bars, counts.values)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
    "             str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite risk score histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(risk_df['composite_risk_score'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(risk_df['composite_risk_score'].mean(), color='red', \n",
    "            linestyle='--', linewidth=2, label=f'Mean: {risk_df[\"composite_risk_score\"].mean():.3f}')\n",
    "plt.axvline(risk_df['composite_risk_score'].median(), color='blue', \n",
    "            linestyle='--', linewidth=2, label=f'Median: {risk_df[\"composite_risk_score\"].median():.3f}')\n",
    "plt.xlabel('Composite Risk Score', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Composite Risk Scores', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sub-Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics for all sub-scores\n",
    "score_columns = [\n",
    "    'urban_density_score',\n",
    "    'climate_anomaly_score',\n",
    "    'seismic_risk_score',\n",
    "    'fire_risk_score',\n",
    "    'flood_risk_score',\n",
    "    'coastal_risk_score'\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SUB-SCORE STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(risk_df[score_columns].describe().T.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for all sub-scores\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "score_labels = [\n",
    "    'Urban Density',\n",
    "    'Climate Anomaly',\n",
    "    'Seismic Risk',\n",
    "    'Fire Risk',\n",
    "    'Flood Risk',\n",
    "    'Coastal Risk'\n",
    "]\n",
    "\n",
    "for i, (col, label) in enumerate(zip(score_columns, score_labels)):\n",
    "    axes[i].boxplot(risk_df[col].dropna(), vert=True)\n",
    "    axes[i].set_title(label, fontsize=12, fontweight='bold')\n",
    "    axes[i].set_ylabel('Score', fontsize=10)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].set_ylim(-0.05, 1.05)\n",
    "\n",
    "plt.suptitle('Risk Sub-Score Distributions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr_matrix = risk_df[score_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1,\n",
    "            xticklabels=[s.replace('_score', '').replace('_', ' ').title() for s in score_columns],\n",
    "            yticklabels=[s.replace('_score', '').replace('_', ' ').title() for s in score_columns])\n",
    "plt.title('Risk Factor Correlation Matrix', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStrong correlations (|r| > 0.5):\")\n",
    "for i in range(len(corr_matrix)):\n",
    "    for j in range(i+1, len(corr_matrix)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.5:\n",
    "            print(f\"{score_columns[i]:25s} <-> {score_columns[j]:25s}: {corr_matrix.iloc[i, j]:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. High-Risk Site Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 highest risk sites\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 20 HIGHEST RISK SITES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "top_20 = risk_df.nlargest(20, 'composite_risk_score')[[\n",
    "    'name', 'country', 'category', 'composite_risk_score', 'risk_level',\n",
    "    'urban_density_score', 'seismic_risk_score', 'climate_anomaly_score'\n",
    "]]\n",
    "\n",
    "print(top_20.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sites in danger status vs risk level\n",
    "danger_risk = pd.crosstab(risk_df['in_danger'], risk_df['risk_level'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"IN DANGER STATUS vs RISK LEVEL\")\n",
    "print(\"=\" * 60)\n",
    "print(danger_risk)\n",
    "\n",
    "# Are sites officially \"in danger\" correlated with high risk scores?\n",
    "in_danger_avg_risk = risk_df.groupby('in_danger')['composite_risk_score'].mean()\n",
    "print(f\"\\nAverage risk score - Not in danger: {in_danger_avg_risk[False]:.3f}\")\n",
    "if True in in_danger_avg_risk:\n",
    "    print(f\"Average risk score - In danger:     {in_danger_avg_risk[True]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Anomaly Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly statistics\n",
    "anomaly_count = risk_df['is_anomaly'].sum()\n",
    "anomaly_pct = (anomaly_count / len(risk_df)) * 100\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ANOMALY DETECTION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total sites: {len(risk_df)}\")\n",
    "print(f\"Anomalous sites: {anomaly_count} ({anomaly_pct:.1f}%)\")\n",
    "print(f\"Normal sites: {len(risk_df) - anomaly_count} ({100-anomaly_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomalous sites list\n",
    "if anomaly_count > 0:\n",
    "    print(\"\\nAnomalous Sites (sorted by Isolation Forest score):\")\n",
    "    anomalies = risk_df[risk_df['is_anomaly'] == True][[\n",
    "        'name', 'country', 'composite_risk_score', 'isolation_forest_score',\n",
    "        'urban_density_score', 'seismic_risk_score', 'climate_anomaly_score'\n",
    "    ]].sort_values('isolation_forest_score').head(20)\n",
    "    \n",
    "    print(anomalies.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest score distribution\n",
    "if 'isolation_forest_score' in risk_df.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0].hist(risk_df['isolation_forest_score'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0].axvline(0, color='red', linestyle='--', linewidth=2, label='Decision Boundary')\n",
    "    axes[0].set_xlabel('Isolation Forest Score', fontsize=12)\n",
    "    axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0].set_title('Isolation Forest Score Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Scatter: IF score vs composite risk\n",
    "    colors = risk_df['is_anomaly'].map({True: 'red', False: 'blue'})\n",
    "    axes[1].scatter(risk_df['composite_risk_score'], risk_df['isolation_forest_score'],\n",
    "                   c=colors, alpha=0.5, s=30)\n",
    "    axes[1].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[1].set_xlabel('Composite Risk Score', fontsize=12)\n",
    "    axes[1].set_ylabel('Isolation Forest Score', fontsize=12)\n",
    "    axes[1].set_title('Anomaly Score vs Risk Score', fontsize=12, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=8, label='Anomaly'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=8, label='Normal')\n",
    "    ]\n",
    "    axes[1].legend(handles=legend_elements)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Geographic Risk Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average risk by country (top 15)\n",
    "country_risk = risk_df.groupby('country').agg({\n",
    "    'composite_risk_score': ['mean', 'count']\n",
    "}).round(3)\n",
    "country_risk.columns = ['avg_risk', 'site_count']\n",
    "country_risk = country_risk[country_risk['site_count'] >= 3]  # At least 3 sites\n",
    "country_risk = country_risk.sort_values('avg_risk', ascending=False).head(15)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TOP 15 COUNTRIES BY AVERAGE RISK\")\n",
    "print(\"(Countries with at least 3 sites)\")\n",
    "print(\"=\" * 60)\n",
    "print(country_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic scatter plot colored by risk\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "scatter = ax.scatter(risk_df['longitude'], risk_df['latitude'],\n",
    "                    c=risk_df['composite_risk_score'],\n",
    "                    cmap='RdYlGn_r',  # Red-Yellow-Green reversed\n",
    "                    s=50, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Mark anomalies with black circles\n",
    "if anomaly_count > 0:\n",
    "    anomalies = risk_df[risk_df['is_anomaly'] == True]\n",
    "    ax.scatter(anomalies['longitude'], anomalies['latitude'],\n",
    "              facecolors='none', edgecolors='black', s=200, linewidth=2,\n",
    "              label='Anomaly', zorder=10)\n",
    "\n",
    "plt.colorbar(scatter, ax=ax, label='Composite Risk Score')\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_title('Geographic Distribution of Risk Scores', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Insights\n",
    "\n",
    "This notebook analyzed the risk scores for UNESCO heritage sites. Key findings:\n",
    "\n",
    "1. **Risk Distribution**: [View the actual distribution from your run]\n",
    "2. **Top Risk Factors**: [Identify which sub-scores have highest values]\n",
    "3. **High-Risk Sites**: [Note the top sites from your analysis]\n",
    "4. **Anomalies**: [Describe anomalous patterns detected]\n",
    "5. **Geographic Patterns**: [Note any regional risk patterns]\n",
    "\n",
    "**Next Steps**:\n",
    "- Investigate specific high-risk sites in detail\n",
    "- Explore mitigation strategies for different risk types\n",
    "- Create interactive visualizations (Notebook 03)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
